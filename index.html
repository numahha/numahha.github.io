<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
<meta http-equiv="Content-Style-Type" content="text/css">
<title>Toru Hishinuma</title>
<style type="text/css">
<!--
a{text-decoration:none;}
a:hover{text-decoration:underline;color:#0000ff;}
a:link {color:#0000ff;}
a:visited{color:#0000ff;}
a:active{color:#0000ff;}
-->
</style>
</head>
<body>

<div id="page">
<div id="header">
 <div id="description">
 <h1>Toru Hishinuma</h1>
        Kyoto University<br>
        Kyoto, Japan<br>
 <b>Email:</b> hishinuma.toru.43n[at]st.kyoto-u.ac.jp
 <br>
 <a href="https://github.com/numahha/">Github</a>
 <br>
 <a href="https://github.com/numahha/numahha.github.io/blob/master/resume_japanese.pdf">Resume (Japanese)</a>
 <br>
 </div>
</div>
<br>
I am currently a Ph.D. student at Kyoto University (Supervisor: Professor <a href="https://www.aa.t.kyoto-u.ac.jp/en/research/introduction/dynamics">Kei Senda</a>)

<br>
<br>
<br>

<h3>Fields of Interests</h3>
<div class="list">
 <ul>
  <li> Robot dynamics and control</li>
  <li> Reinforcement learning </li>
  <li> Bayesian inference </li>
 </ul>
</div>

<br>

<h3>Journal Papers</h3>

<ol><li>
K. Senda, <b><u>T. Hishinuma</u></b>, and Y. Tani,
"Approximate Bayesian Reinforcement Learning based on Estimation of Plant", <i><b>Autonomous Robots</b></i>, 44-5, 845--857, 2020.

</li><li>
K. Senda, S. Hattori, <b><u>T. Hishinuma</u></b>, and T. Kohda,
"Acceleration of Reinforcement Learning by Policy Evaluation Using Nonstationary Iterative Method",
<i><b>IEEE Transactions on Cybernetics</b></i>,
44-12, 2696-2705, 2014.

</li></ol>

<br>

<h3>Conference Papers</h3>

<ol><li>
<b><u>T. Hishinuma</u></b>, and K. Senda,
"An Approximate Bayesian Reinforcement Learning Approach Using Robust Control Policy and Tree Search",
International Conference on Automated Planning and Scheduling (ICAPS),
pp. 417-421, Delft, Netherlands, 2018.

</li><li>
<b><u>T. Hishinuma</u></b>, and K. Senda,
"Robust and explorative behavior in model-based Bayesian reinforcement learning",
IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL),
Athens, Greece, 2016.

</li></ol>

<br>

<h3>Education</h3>
<div class="list">
 <ul>
  <li> MEng, Kyoto University, Graduate School of Engineering, Department of Aeronautics and Astronautics, 2015.</li>
  <li> BEng, Kyoto University, Department of Engineering Science, Aeronautics and Astronautics Course, 2013.
 </ul>
</div>

</body></html>
