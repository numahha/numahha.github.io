<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-D74KSKE7HE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-D74KSKE7HE');
</script>
 
<meta http-equiv="Content-Style-Type" content="text/css">
<title>Toru Hishinuma</title>
<style type="text/css">
<!--
a{text-decoration:none;}
a:hover{text-decoration:underline;color:#0000ff;}
a:link {color:#0000ff;}
a:visited{color:#0000ff;}
a:active{color:#0000ff;}
-->
</style>
</head>
<body>

<div id="page">
<div id="header">
 <div id="description">
 <h1>Toru Hishinuma</h1>
 <br>
 Engineer at <a href="https://proxima-ai-tech.com/">Proxima Technology Inc.</a>
 <br>
 toru.hishinuma[at]proxima-ai-tech.com (work), numahha[at]gmail.com (private)
 <br>
 <a href="https://github.com/numahha/">Github</a>
 <br>
 <br>
 <a href="https://scholar.google.co.jp/citations?user=Xqx8daIAAAAJ&hl=ja&oi=ao">Google Scholar</a>
 <br>
 </div>
</div>

<br>
<br>
<br>

<h3>Fields of Interests</h3>
<div class="list">
 <ul>
  <li> Robot dynamics and control </li>
  <li> Model-based reinforcement learning </li>
  <li> Numerical optimal control </li>
  <li> Variational inference </li>
 </ul>
</div>

<br>

<h3>Journal Papers</h3>

<ol><li>
T. Hishinuma, K. Senda, 
"Importance-weighted variational inference model estimation for offline Bayesian model-based reinforcement learning", IEEE Access, accepted.
  
</li><li>
K. Senda, T. Hishinuma, Y. Tani,
"Approximate Bayesian Reinforcement Learning based on Estimation of Plant", Autonomous Robots, 44-5, 845--857, 2020.

</li><li>
K. Senda, S. Hattori, T. Hishinuma, T. Kohda,
"Acceleration of Reinforcement Learning by Policy Evaluation Using Nonstationary Iterative Method",
IEEE Transactions on Cybernetics,
44-12, 2696-2705, 2014.

</li></ol>

<br>

<h3>Conference Papers</h3>

<ol><li>
T. Hishinuma, K. Senda,
"Weighted model estimation for offline model-based reinforcement learning",
Neural Information Processing Systems (NeurIPS), 2021.
</li><li>

T. Hishinuma, K. Senda,
"An Approximate Bayesian Reinforcement Learning Approach Using Robust Control Policy and Tree Search",
International Conference on Automated Planning and Scheduling (ICAPS),
pp. 417-421, 2018.

</li><li>
T. Hishinuma, K. Senda,
"Robust and explorative behavior in model-based Bayesian reinforcement learning",
IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (IEEE ADPRL), 2016.

</li></ol>

<br>

<h3>Education</h3>
<div class="list">
 <ul>
  <li> MEng, Kyoto University, Graduate School of Engineering, Department of Aeronautics and Astronautics, 2015.</li>
  <li> BEng, Kyoto University, Department of Engineering Science, Aeronautics and Astronautics Course, 2013.
 </ul>
</div>

</body></html>
